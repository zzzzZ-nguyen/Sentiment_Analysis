import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from wordcloud import WordCloud

# ==================================================
# üì¶ LOAD RESOURCES
# ==================================================
@st.cache_resource
def load_resources():
    # ƒê∆∞·ªùng d·∫´n file (B·∫°n ch·ªânh l·∫°i cho ƒë√∫ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø)
    model_path = os.path.join("models", "model_en.pkl")
    vectorizer_path = os.path.join("models", "vectorizer_en.pkl")
    
    # ‚ö†Ô∏è L∆ØU √ù: ƒê·ªÉ t·ª± ƒë·ªông c·∫≠p nh·∫≠t, b·∫°n n√™n load file CSV d·ªØ li·ªáu th·∫≠t
    # V√≠ d·ª•: data = pd.read_csv("data/processed_data.csv")
    # ·ªû ƒë√¢y m√¨nh t·∫°o d·ªØ li·ªáu gi·∫£ l·∫≠p ƒë·ªÉ code ch·∫°y ƒë∆∞·ª£c ngay
    data = pd.DataFrame({
        "review_clean": [
            "good product", "excellent service", "bad quality", "terrible experience", 
            "waste of money", "highly recommend", "average item", "not worth it",
            "very happy", "disappointed", "love it", "hate it", "neutral feeling"
        ],
        "label": [
            "positive", "positive", "negative", "negative", 
            "negative", "positive", "neutral", "negative",
            "positive", "negative", "positive", "negative", "neutral"
        ]
    })

    try:
        model = joblib.load(model_path)
        vectorizer = joblib.load(vectorizer_path)
        return model, vectorizer, data
    except Exception as e:
        return None, None, data

# ==================================================
# üìä TRAINING INFO FUNCTION
# ==================================================
def show():
    st.markdown("<h2 style='color:#E58E61;'>‚öôÔ∏è Training Pipeline & Model Evaluation</h2>", unsafe_allow_html=True)
    st.write("Th√¥ng tin chi ti·∫øt v·ªÅ qu√° tr√¨nh hu·∫•n luy·ªán, ƒë√°nh gi√° hi·ªáu nƒÉng v√† gi·∫£i th√≠ch m√¥ h√¨nh.")

    model, vectorizer, data = load_resources()

    if model is None:
        st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file model (.pkl). Vui l√≤ng ki·ªÉm tra th∆∞ m·ª•c 'models/'.")
        return

    # T√°ch d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° (Trong th·ª±c t·∫ø n√™n d√πng t·∫≠p Test ri√™ng)
    X_test = data["review_clean"]
    y_test = data["label"]
    
    # D·ª± ƒëo√°n th·ªùi gian th·ª±c ƒë·ªÉ l·∫•y ch·ªâ s·ªë
    X_tfidf = vectorizer.transform(X_test)
    y_pred = model.predict(X_tfidf)

    # --- TABS GIAO DI·ªÜN ---
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Dataset Stats", "üìà Model Performance", "üß† Feature Importance", "üîç Model Params"])

    # ==================================================
    # TAB 1: DATASET STATISTICS
    # ==================================================
    with tab1:
        st.subheader("1. D·ªØ li·ªáu hu·∫•n luy·ªán")
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.write("**Class Distribution:**")
            dist_df = data['label'].value_counts()
            st.dataframe(dist_df, use_container_width=True)
            
            # Bi·ªÉu ƒë·ªì tr√≤n ph√¢n b·ªë
            fig, ax = plt.subplots(figsize=(4, 4))
            ax.pie(dist_df, labels=dist_df.index, autopct='%1.1f%%', colors=['#66b3ff','#99ff99','#ffcc99'])
            st.pyplot(fig)

        with col2:
            st.write("**Word Cloud (T·ª´ kh√≥a ph·ªï bi·∫øn):**")
            text = " ".join(review for review in data.review_clean)
            wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(text)
            
            fig_wc, ax_wc = plt.subplots()
            ax_wc.imshow(wordcloud, interpolation='bilinear')
            ax_wc.axis("off")
            st.pyplot(fig_wc)

    # ==================================================
    # TAB 2: PERFORMANCE METRICS (T·ª∞ ƒê·ªòNG T√çNH)
    # ==================================================
    with tab2:
        st.subheader("2. Hi·ªáu nƒÉng m√¥ h√¨nh (Real-time Calculation)")
        
        # T√≠nh to√°n metrics
        acc = accuracy_score(y_test, y_pred)
        # S·ª≠ d·ª•ng average='weighted' v√¨ ƒë√¢y l√† b√†i to√°n ƒëa l·ªõp (3 l·ªõp: pos, neg, neu)
        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)
        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

        # Hi·ªÉn th·ªã Metrics d·∫°ng Card ƒë·∫πp
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("Accuracy", f"{acc:.2%}", delta="Goal: >85%")
        m2.metric("Precision", f"{prec:.2%}")
        m3.metric("Recall", f"{rec:.2%}")
        m4.metric("F1-Score", f"{f1:.2%}")

        st.divider()

        # Confusion Matrix
        col_cm1, col_cm2 = st.columns([2, 1])
        with col_cm1:
            st.markdown("##### Confusion Matrix")
            cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
            
            fig_cm, ax_cm = plt.subplots(figsize=(6, 4))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
            plt.ylabel('Th·ª±c t·∫ø')
            plt.xlabel('D·ª± ƒëo√°n')
            st.pyplot(fig_cm)
        
        with col_cm2:
            st.info("""
            **Gi·∫£i th√≠ch:**
            - **ƒê∆∞·ªùng ch√©o ch√≠nh (M√†u ƒë·∫≠m):** S·ªë l∆∞·ª£ng d·ª± ƒëo√°n ƒë√∫ng.
            - **C√°c √¥ kh√°c:** S·ªë l∆∞·ª£ng d·ª± ƒëo√°n sai.
            - D·ªØ li·ªáu n√†y ƒë∆∞·ª£c t√≠nh to√°n tr·ª±c ti·∫øp t·ª´ t·∫≠p d·ªØ li·ªáu t·∫£i l√™n.
            """)

    # ==================================================
    # TAB 3: FEATURE IMPORTANCE (PH·∫¶N X·ªäN NH·∫§T)
    # ==================================================
    with tab3:
        st.subheader("3. M√¥ h√¨nh h·ªçc ƒë∆∞·ª£c g√¨? (Feature Importance)")
        st.caption("C√°c t·ª´ ng·ªØ ·∫£nh h∆∞·ªüng nhi·ªÅu nh·∫•t ƒë·∫øn quy·∫øt ƒë·ªãnh c·ªßa m√¥ h√¨nh Logistic Regression.")

        if hasattr(model, 'coef_'):
            # L·∫•y t√™n c√°c feature t·ª´ vectorizer
            feature_names = vectorizer.get_feature_names_out()
            
            # L·∫•y h·ªá s·ªë (coefficient) c·ªßa t·ª´ng class
            # Gi·∫£ s·ª≠ class 'positive' n·∫±m ·ªü index n√†o ƒë√≥, ta c·∫ßn t√¨m index ƒë√≥
            classes = model.classes_
            
            # Ch·ªçn class ƒë·ªÉ xem
            selected_class = st.selectbox("Ch·ªçn nh√£n c·∫£m x√∫c ƒë·ªÉ xem t·ª´ kh√≥a ƒë·∫∑c tr∆∞ng:", classes)
            class_index = np.where(classes == selected_class)[0][0]
            
            # L·∫•y top 10 t·ª´ kh√≥a ·∫£nh h∆∞·ªüng nh·∫•t
            coefs = model.coef_[class_index]
            
            # S·∫Øp x·∫øp
            top_positive_indices = np.argsort(coefs)[-10:] # Top 10 gi√° tr·ªã l·ªõn nh·∫•t (t√≠ch c·ª±c cho class n√†y)
            top_negative_indices = np.argsort(coefs)[:10]  # Top 10 gi√° tr·ªã nh·ªè nh·∫•t (ti√™u c·ª±c cho class n√†y)

            col_f1, col_f2 = st.columns(2)
            
            with col_f1:
                st.markdown(f"**Top t·ª´ kh√≥a ƒê·∫∂C TR∆ØNG cho '{selected_class}'** (H·ªá s·ªë cao)")
                top_words = [feature_names[i] for i in top_positive_indices]
                top_scores = coefs[top_positive_indices]
                
                df_top = pd.DataFrame({'Word': top_words, 'Score': top_scores})
                st.bar_chart(df_top.set_index('Word'), color="#2b6f3e")

            with col_f2:
                st.markdown(f"**Top t·ª´ kh√≥a CH·ªêNG L·∫†I '{selected_class}'** (H·ªá s·ªë th·∫•p)")
                neg_words = [feature_names[i] for i in top_negative_indices]
                neg_scores = coefs[top_negative_indices]
                
                df_neg = pd.DataFrame({'Word': neg_words, 'Score': neg_scores})
                st.bar_chart(df_neg.set_index('Word'), color="#A20409")

        else:
            st.warning("M√¥ h√¨nh n√†y kh√¥ng h·ªó tr·ª£ tr√≠ch xu·∫•t Feature Importance (VD: SVM kernel rbf).")

    # ==================================================
    # TAB 4: MODEL PARAMETERS
    # ==================================================
    with tab4:
        st.subheader("4. Th√¥ng s·ªë k·ªπ thu·∫≠t")
        
        p1, p2 = st.columns(2)
        with p1:
            st.markdown("### üìå Model Configuration")
            st.json({
                "Type": type(model).__name__,
                "Solver": getattr(model, 'solver', 'N/A'),
                "C (Regularization)": getattr(model, 'C', 'N/A'),
                "Max Iterations": getattr(model, 'max_iter', 'N/A'),
                "Classes": list(model.classes_)
            })

        with p2:
            st.markdown("### üìå Vectorizer Configuration")
            st.json({
                "Type": type(vectorizer).__name__,
                "Vocabulary Size": len(vectorizer.vocabulary_),
                "N-gram Range": vectorizer.ngram_range,
                "Analyzer": vectorizer.analyzer
            })
            
    st.write("---")
    st.caption("¬© 2025 Auto-generated Report based on loaded `.pkl` models.")
