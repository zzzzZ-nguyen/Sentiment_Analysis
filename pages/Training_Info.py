import streamlit as st
import pandas as pd
import os
import matplotlib.pyplot as plt

# --- Cáº¥u hÃ¬nh thÆ° viá»‡n váº½ hÃ¬nh ---
try:
    from wordcloud import WordCloud
    HAS_WORDCLOUD = True
except ImportError:
    HAS_WORDCLOUD = False

try:
    import plotly.express as px
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

# ==================================================
# 1. Cáº¤U HÃŒNH GIAO DIá»†N
# ==================================================
st.set_page_config(page_title="Data & Training Info", page_icon="ğŸ“Š", layout="wide")

# CSS Vintage Style
st.markdown("""
<style>
    [data-testid="stAppViewContainer"] {
        background-color: #F0EBD6;
        background-image: repeating-linear-gradient(45deg, #F0EBD6 0, #F0EBD6 2px, #E8E4CC 2px, #E8E4CC 4px);
    }
    h1, h2, h3 { color: #2b6f3e !important; font-family: 'Segoe UI', sans-serif; }
    div[data-testid="stMetric"] {
        background-color: white;
        padding: 15px; border-radius: 8px;
        border-left: 5px solid #2b6f3e;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stTabs [data-baseweb="tab-list"] button [data-testid="stMarkdownContainer"] p {
        font-size: 1.1rem; font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# ==================================================
# 2. HÃ€M Äá»ŒC Dá»® LIá»†U
# ==================================================
@st.cache_data
def load_training_data():
    """Äá»c dá»¯ liá»‡u Train/Test"""
    data_dir = "data"
    all_data = []
    
    # 1. Äá»ŒC Táº¬P TRAIN
    train_files = {
        "Negative": "train_negative_tokenized.txt",
        "Neutral": "train_neutral_tokenized.txt",
        "Positive": "train_positive_tokenized.txt"
    }
    
    if not os.path.exists(data_dir): return pd.DataFrame(), False

    for label, filename in train_files.items():
        path = os.path.join(data_dir, filename)
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
                for line in lines:
                    if line.strip():
                        all_data.append({"Content": line.strip(), "Label": label, "Type": "Train"})

    # 2. Äá»ŒC Táº¬P TEST (Náº¿u cÃ³)
    test_path = os.path.join(data_dir, "test_tokenized_ANS.txt")
    if os.path.exists(test_path):
        with open(test_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
            for i in range(0, len(lines) - 1, 2):
                text = lines[i].strip()
                label_code = lines[i+1].strip()
                if label_code == 'NEG': label = "Negative"
                elif label_code == 'POS': label = "Positive"
                else: label = "Neutral"
                
                if text:
                    all_data.append({"Content": text, "Label": label, "Type": "Test"})
    
    return pd.DataFrame(all_data), True

@st.cache_data
def load_lexicon_data():
    """Äá»c dá»¯ liá»‡u Tá»« Ä‘iá»ƒn (Lexicon) cÃ³ xá»­ lÃ½ lá»—i dÃ²ng há»ng"""
    file_path = "data/vietnamese_lexicon.txt"
    if not os.path.exists(file_path): return None
    
    lexicon_data = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f):
            # Bá» qua dÃ²ng trá»‘ng hoáº·c comment
            line = line.strip()
            if not line or line.startswith('#'):
                continue
                
            parts = line.split()
            
            # Cáº¥u trÃºc mong Ä‘á»£i: [Loáº¡i tá»«, ID, PosScore, NegScore, Word#ID, Definition...]
            if len(parts) >= 5:
                try:
                    # ThÃªm try-except Ä‘á»ƒ náº¿u dÃ²ng nÃ o sá»‘ liá»‡u sai thÃ¬ bá» qua luÃ´n
                    pos_score = float(parts[2])
                    neg_score = float(parts[3])
                    
                    word = parts[4].split('#')[0].replace('_', ' ') 
                    definition = " ".join(parts[5:]).strip('"')
                    
                    lexicon_data.append({
                        "Tá»« vá»±ng": word,
                        "Loáº¡i tá»«": parts[0],
                        "Äiá»ƒm TÃ­ch cá»±c": pos_score,
                        "Äiá»ƒm TiÃªu cá»±c": neg_score,
                        "Äá»‹nh nghÄ©a": definition
                    })
                except ValueError:
                    # Náº¿u dÃ²ng nÃ y khÃ´ng pháº£i sá»‘ (vÃ­ dá»¥ dÃ²ng header), bá» qua nÃ³
                    continue
                    
    if not lexicon_data:
        return None
        
    return pd.DataFrame(lexicon_data)

# ==================================================
# 3. GIAO DIá»†N CHÃNH
# ==================================================
st.title("ğŸ“Š Dashboard Dá»¯ liá»‡u & Tá»« Ä‘iá»ƒn")
st.write("Quáº£n lÃ½ dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  tá»« Ä‘iá»ƒn cáº£m xÃºc.")

df_train, found_train = load_training_data()
df_lexicon = load_lexicon_data()

# --- METRICS ---
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("Máº«u Train/Test", f"{len(df_train):,}" if found_train else "0")
with col2:
    st.metric("Tá»« trong tá»« Ä‘iá»ƒn", f"{len(df_lexicon):,}" if df_lexicon is not None else "0")
with col3:
    if found_train:
        pos_cnt = len(df_train[df_train['Label']=='Positive'])
        st.metric("Máº«u TÃ­ch cá»±c", f"{pos_cnt:,}")
    else: st.metric("Máº«u TÃ­ch cá»±c", "0")
with col4:
    if df_lexicon is not None:
        avg_pos = df_lexicon['Äiá»ƒm TÃ­ch cá»±c'].mean()
        st.metric("Pos Score TB", f"{avg_pos:.2f}")
    else: st.metric("Pos Score TB", "0")

st.divider()

# --- TABS ---
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“š Tá»« Äiá»ƒn Cáº£m XÃºc", "ğŸ“ˆ PhÃ¢n Bá»‘", "â˜ï¸ WordCloud", "ğŸ“‹ Dá»¯ Liá»‡u Train"])

# TAB 1: Tá»ª ÄIá»‚N (NEW)
with tab1:
    st.subheader("ğŸ“š Tá»« Ä‘iá»ƒn SentiWordNet (Vietnamese)")
    if df_lexicon is not None:
        st.dataframe(
            df_lexicon, 
            column_config={
                "Äiá»ƒm TÃ­ch cá»±c": st.column_config.ProgressColumn("Positive Score", format="%.2f", min_value=0, max_value=1, help="Äiá»ƒm cÃ ng cao cÃ ng tÃ­ch cá»±c"),
                "Äiá»ƒm TiÃªu cá»±c": st.column_config.ProgressColumn("Negative Score", format="%.2f", min_value=0, max_value=1, help="Äiá»ƒm cÃ ng cao cÃ ng tiÃªu cá»±c"),
            },
            use_container_width=True,
            height=500
        )
    else:
        st.warning("âš ï¸ ChÆ°a tÃ¬m tháº¥y file `data/vietnamese_lexicon.txt`.")
        st.info("HÃ£y táº¡o file nÃ y vÃ  dÃ¡n dá»¯ liá»‡u tá»« Ä‘iá»ƒn vÃ o.")

# TAB 2: CHARTS
with tab2:
    if found_train and not df_train.empty:
        c1, c2 = st.columns(2)
        with c1:
            st.subheader("Tá»· lá»‡ nhÃ£n")
            counts = df_train['Label'].value_counts().reset_index()
            counts.columns = ['Label', 'Count']
            if HAS_PLOTLY:
                fig = px.pie(counts, values='Count', names='Label', hole=0.5, color='Label',
                             color_discrete_map={'Positive':'#2ecc71', 'Negative':'#e74c3c', 'Neutral':'#f1c40f'})
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.bar_chart(df_train['Label'].value_counts())
        with c2:
            st.subheader("Train vs Test")
            st.bar_chart(df_train['Type'].value_counts())
    else:
        st.info("ChÆ°a cÃ³ dá»¯ liá»‡u Train/Test Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“.")

# TAB 3: WORDCLOUD
with tab3:
    st.subheader("â˜ï¸ ÄÃ¡m mÃ¢y tá»« vá»±ng")
    if found_train and HAS_WORDCLOUD:
        selected_sentiment = st.radio("Chá»n nhÃ£n:", ["Positive", "Negative"], horizontal=True)
        subset = df_train[df_train['Label'] == selected_sentiment]
        text = " ".join(subset['Content'].astype(str))
        if text:
            wc = WordCloud(width=800, height=300, background_color='white').generate(text)
            fig_wc, ax = plt.subplots(figsize=(10, 4))
            ax.imshow(wc, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig_wc)
        else:
            st.warning("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ táº¡o WordCloud.")

# TAB 4: DATA TABLE
with tab4:
    st.subheader("ğŸ” Dá»¯ liá»‡u Huáº¥n luyá»‡n thÃ´")
    if found_train:
        st.dataframe(df_train, use_container_width=True)
    else:
        st.warning("KhÃ´ng cÃ³ dá»¯ liá»‡u.")

