import streamlit as st
import os
import pickle
import numpy as np

# --- C·∫•u h√¨nh th∆∞ vi·ªán PyTorch ---
try:
    import torch
    import torch.nn as nn
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False

# ==========================================
# 1. ƒê·ªäNH NGHƒ®A L·∫†I MODEL (B·∫Øt bu·ªôc ph·∫£i gi·ªëng l√∫c Train)
# ==========================================
if HAS_TORCH:
    class SentimentLSTM(nn.Module):
        def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, n_layers, drop_prob=0.5):
            super(SentimentLSTM, self).__init__()
            self.embedding = nn.Embedding(vocab_size, embed_dim)
            self.lstm = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)
            self.dropout = nn.Dropout(drop_prob)
            self.fc = nn.Linear(hidden_dim, output_dim)
            self.sigmoid = nn.Sigmoid()

        def forward(self, x, hidden):
            batch_size = x.size(0)
            embeds = self.embedding(x)
            lstm_out, hidden = self.lstm(embeds, hidden)
            lstm_out = lstm_out.contiguous().view(-1, hidden_dim)
            out = self.dropout(lstm_out)
            out = self.fc(out)
            out = self.sigmoid(out)
            out = out.view(batch_size, -1)
            out = out[:, -1]
            return out, hidden

        def init_hidden(self, batch_size, device):
            weight = next(self.parameters()).data
            hidden = (weight.new(n_layers, batch_size, hidden_dim).zero_().to(device),
                      weight.new(n_layers, batch_size, hidden_dim).zero_().to(device))
            return hidden
    
    # C·∫•u h√¨nh Hyperparameters (Ph·∫£i kh·ªõp v·ªõi file train)
    EMBEDDING_DIM = 400
    HIDDEN_DIM = 256 # Ho·∫∑c 128 t√πy b·∫°n ch·ªânh l√∫c train
    N_LAYERS = 2

# ==========================================
# 2. H√ÄM X·ª¨ L√ù TEXT & LOAD MODEL
# ==========================================
def load_resources():
    # Load Vocab
    vocab_path = "models/vocab.pkl" # ƒê·∫£m b·∫£o b·∫°n ƒë√£ l∆∞u file n√†y l√∫c train
    model_path = "models/sentiment_model.pth" # ƒê·∫£m b·∫£o file n√†y t·ªìn t·∫°i
    
    vocab = None
    model = None
    
    if os.path.exists(vocab_path):
        with open(vocab_path, 'rb') as f:
            vocab = pickle.load(f)
            
    if HAS_TORCH and os.path.exists(model_path) and vocab:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        vocab_size = len(vocab) + 1
        model = SentimentLSTM(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, 1, N_LAYERS)
        # Load state dict
        try:
            model.load_state_dict(torch.load(model_path, map_location=device))
            model.to(device)
            model.eval()
        except:
            model = None # L·ªói sai c·∫•u tr√∫c model
            
    return vocab, model

def predict_sentiment(text, vocab, model):
    if not vocab or not model:
        return None, 0.0

    # Tokenize
    words = text.split()
    review_int = []
    for word in words:
        review_int.append(vocab.get(word, 0)) # 0 l√† padding/unknown
    
    # Pad/Truncate v·ªÅ 50
    seq_len = 50
    if len(review_int) < seq_len:
        features = list(np.zeros(seq_len - len(review_int), dtype=int)) + review_int
    else:
        features = review_int[:seq_len]
    
    # Convert to Tensor
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    feature_tensor = torch.tensor([features], dtype=torch.long).to(device)
    h = model.init_hidden(1, device)
    
    # Predict
    with torch.no_grad():
        output, _ = model(feature_tensor, h)
        pred = output.item()
    
    return pred # Tr·∫£ v·ªÅ gi√° tr·ªã 0.0 -> 1.0

# ==========================================
# 3. GIAO DI·ªÜN CH√çNH (H√†m show)
# ==========================================
def show():
    # KH√îNG D√ôNG st.set_page_config()
    
    st.markdown('<div style="background-color:rgba(255,255,255,0.9); padding:20px; border-radius:15px;">', unsafe_allow_html=True)
    st.title("üß† Ph√¢n T√≠ch C·∫£m X√∫c (Deep Learning)")
    st.write("S·ª≠ d·ª•ng m√¥ h√¨nh LSTM ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n b√¨nh lu·∫≠n m·ªõi.")

    if not HAS_TORCH:
        st.error("Ch∆∞a c√†i ƒë·∫∑t PyTorch.")
        st.markdown('</div>', unsafe_allow_html=True)
        return

    # Load Model
    vocab, model = load_resources()

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("Nh·∫≠p b√¨nh lu·∫≠n:")
        user_input = st.text_area("N·ªôi dung ƒë√°nh gi√°:", height=150, placeholder="V√≠ d·ª•: S·∫£n ph·∫©m d√πng r·∫•t t·ªët, giao h√†ng nhanh...")
        
        btn_predict = st.button("üöÄ Ph√¢n T√≠ch Ngay", type="primary")
        
        if btn_predict:
            if not user_input.strip():
                st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung!")
            elif model is None:
                st.error("‚ö†Ô∏è Ch∆∞a t√¨m th·∫•y Model! Vui l√≤ng v√†o trang 'Train PyTorch' ƒë·ªÉ hu·∫•n luy·ªán tr∆∞·ªõc.")
            else:
                with st.spinner("ƒêang ph√¢n t√≠ch..."):
                    score = predict_sentiment(user_input, vocab, model)
                    
                    st.divider()
                    st.markdown("### K·∫øt qu·∫£ d·ª± ƒëo√°n:")
                    
                    # Logic hi·ªÉn th·ªã: < 0.4 l√† Negative, > 0.6 l√† Positive, ·ªü gi·ªØa l√† Neutral
                    if score >= 0.6:
                        st.success(f"D·ª± ƒëo√°n: **T√çCH C·ª∞C (Positive)**")
                        st.metric("ƒê·ªô tin c·∫≠y", f"{score:.2%}")
                    elif score <= 0.4:
                        st.error(f"D·ª± ƒëo√°n: **TI√äU C·ª∞C (Negative)**")
                        st.metric("ƒê·ªô tin c·∫≠y", f"{(1-score):.2%}")
                    else:
                        st.warning(f"D·ª± ƒëo√°n: **TRUNG T√çNH (Neutral)**")
                        st.metric("ƒêi·ªÉm s·ªë", f"{score:.2f}")

    with col2:
        st.info("‚ÑπÔ∏è **Th√¥ng tin:**\n\nƒê√¢y l√† m√¥ h√¨nh LSTM (Long Short-Term Memory) h·ªçc tr√™n m·ª©c ƒë·ªô t·ª´ (Word-level).\n\nK·∫øt qu·∫£ tr·∫£ v·ªÅ l√† x√°c su·∫•t (0-1):"
                "\n- C√†ng g·∫ßn 1: T√≠ch c·ª±c"
                "\n- C√†ng g·∫ßn 0: Ti√™u c·ª±c")
        
        if model:
            st.success("‚úÖ Model ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!")
        else:
            st.error("‚ùå Ch∆∞a c√≥ Model (H√£y Train tr∆∞·ªõc)")

    st.markdown('</div>', unsafe_allow_html=True)
