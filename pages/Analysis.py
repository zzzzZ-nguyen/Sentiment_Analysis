import streamlit as st
import os
import pickle
import numpy as np

# --- C·∫•u h√¨nh th∆∞ vi·ªán PyTorch ---
try:
    import torch
    import torch.nn as nn
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False

# ==========================================
# 1. ƒê·ªäNH NGHƒ®A L·∫†I MODEL (B·∫Øt bu·ªôc ph·∫£i kh·ªõp v·ªõi file Train)
# ==========================================
if HAS_TORCH:
    class SentimentLSTM(nn.Module):
        def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, n_layers, drop_prob=0.5):
            super(SentimentLSTM, self).__init__()
            self.embedding = nn.Embedding(vocab_size, embed_dim)
            self.lstm = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)
            self.dropout = nn.Dropout(drop_prob)
            self.fc = nn.Linear(hidden_dim, output_dim)
            self.sigmoid = nn.Sigmoid()

        def forward(self, x, hidden):
            batch_size = x.size(0)
            embeds = self.embedding(x)
            lstm_out, hidden = self.lstm(embeds, hidden)
            lstm_out = lstm_out.contiguous().view(-1, hidden_dim)
            out = self.dropout(lstm_out)
            out = self.fc(out)
            out = self.sigmoid(out)
            out = out.view(batch_size, -1)
            out = out[:, -1]
            return out, hidden

        def init_hidden(self, batch_size, device):
            weight = next(self.parameters()).data
            hidden = (weight.new(n_layers, batch_size, hidden_dim).zero_().to(device),
                      weight.new(n_layers, batch_size, hidden_dim).zero_().to(device))
            return hidden
    
    # C·∫•u h√¨nh Hyperparameters (L·∫•y t·ª´ file train_pytorch.py)
    EMBEDDING_DIM = 400
    HIDDEN_DIM = 256 
    N_LAYERS = 2

# ==========================================
# 2. H√ÄM X·ª¨ L√ù TEXT & LOAD MODEL
# ==========================================
@st.cache_resource
def load_pytorch_model():
    # ƒê∆∞·ªùng d·∫´n file model v√† vocab
    vocab_path = "models/vocab.pkl"
    model_path = "models/sentiment_model.pth"
    
    vocab = None
    model = None
    
    # 1. Load Vocab
    if os.path.exists(vocab_path):
        with open(vocab_path, 'rb') as f:
            vocab = pickle.load(f)
    
    # 2. Load Model Architecture & State
    if HAS_TORCH and os.path.exists(model_path) and vocab:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        vocab_size = len(vocab) + 1
        
        # Kh·ªüi t·∫°o ki·∫øn tr√∫c model
        model = SentimentLSTM(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, 1, N_LAYERS)
        
        try:
            # Load tr·ªçng s·ªë ƒë√£ train
            model.load_state_dict(torch.load(model_path, map_location=device))
            model.to(device)
            model.eval() # Ch·∫ø ƒë·ªô d·ª± ƒëo√°n (kh√¥ng train)
        except Exception as e:
            print(f"L·ªói load model: {e}")
            model = None 
            
    return vocab, model

def predict_sentiment(text, vocab, model):
    if not vocab or not model:
        return 0.5 # Gi√° tr·ªã m·∫∑c ƒë·ªãnh n·∫øu l·ªói

    # Tokenize (Chuy·ªÉn ch·ªØ th√†nh s·ªë d·ª±a tr√™n vocab)
    words = text.split()
    review_int = []
    for word in words:
        review_int.append(vocab.get(word, 0)) # 0 l√† padding/unknown
    
    # Padding / Truncating v·ªÅ ƒë·ªô d√†i 50
    seq_len = 50
    if len(review_int) < seq_len:
        features = list(np.zeros(seq_len - len(review_int), dtype=int)) + review_int
    else:
        features = review_int[:seq_len]
    
    # Ch·∫°y qua Model
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    feature_tensor = torch.tensor([features], dtype=torch.long).to(device)
    h = model.init_hidden(1, device)
    
    with torch.no_grad():
        output, _ = model(feature_tensor, h)
        pred = output.item() # Tr·∫£ v·ªÅ x√°c su·∫•t (0.0 -> 1.0)
    
    return pred

# ==========================================
# 3. GIAO DI·ªÜN CH√çNH (H√†m Show)
# ==========================================
def show():
    # --- CSS STYLING (Gi·ªëng code m·∫´u c·ªßa b·∫°n) ---
    st.markdown("""
    <style>
    div.stButton > button {
        background-color: #2b6f3e; color: white; border-radius: 5px; width: 100%;
        font-weight: bold;
    }
    .stTextArea textarea {
        background-color: #ffffff;
        color: #333;
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("<h2 style='color:#2b6f3e;'>üß† Deep Learning Sentiment Analysis</h2>", unsafe_allow_html=True)
    st.write("S·ª≠ d·ª•ng m√¥ h√¨nh LSTM (PyTorch) ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán t·ª´ d·ªØ li·ªáu c·ªßa b·∫°n.")

    if not HAS_TORCH:
        st.error("‚ö†Ô∏è Th∆∞ vi·ªán `torch` ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.")
        return

    # Load Model
    vocab, model = load_pytorch_model()

    if model is None:
        st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Model! Vui l√≤ng v√†o trang **Train PyTorch** v√† b·∫•m 'B·∫Øt ƒë·∫ßu Hu·∫•n luy·ªán' tr∆∞·ªõc.")
        st.stop()

    # Chia c·ªôt giao di·ªán
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("### üìù Input Review")
        user_input = st.text_area("Nh·∫≠p n·ªôi dung ƒë√°nh gi√° (Review):", height=150, placeholder="V√≠ d·ª•: S·∫£n ph·∫©m n√†y d√πng r·∫•t t·ªët, pin tr√¢u...")
        
        if st.button("üöÄ Analyze Sentiment"):
            if user_input.strip():
                # D·ª± ƒëo√°n
                with st.spinner("ƒêang ph√¢n t√≠ch..."):
                    score = predict_sentiment(user_input, vocab, model)
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.write("---")
                st.markdown("### üéØ Result")
                
                # Logic: > 0.6 l√† Positive, < 0.4 l√† Negative, c√≤n l·∫°i l√† Neutral
                if score >= 0.6:
                    st.success(f"**POSITIVE (T√≠ch c·ª±c)**\n\nƒê·ªô tin c·∫≠y: {score:.2%}")
                    st.balloons()
                elif score <= 0.4:
                    st.error(f"**NEGATIVE (Ti√™u c·ª±c)**\n\nƒê·ªô tin c·∫≠y: {(1-score):.2%}")
                else:
                    st.warning(f"**NEUTRAL (Trung t√≠nh)**\n\nƒêi·ªÉm s·ªë: {score:.2f}")
            else:
                st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung vƒÉn b·∫£n.")

    with col2:
        st.markdown("### ‚ÑπÔ∏è Examples")
        st.info("**Positive:**\n- S·∫£n ph·∫©m d√πng r·∫•t t·ªët.\n- Giao h√†ng nhanh, ƒë√≥ng g√≥i ƒë·∫πp.")
        st.error("**Negative:**\n- H√†ng k√©m ch·∫•t l∆∞·ª£ng.\n- M·ªõi d√πng ƒë√£ h·ªèng.")
        st.warning("**Neutral:**\n- T·∫°m ƒë∆∞·ª£c.\n- C≈©ng b√¨nh th∆∞·ªùng.")

    st.write("---")
