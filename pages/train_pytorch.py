import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import pickle
from collections import Counter

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N IMPORT ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
try:
    from model_utils import SentimentLSTM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import TensorDataset, DataLoader
    HAS_DEPS = True
except ImportError:
    HAS_DEPS = False

# ==========================================
# 1. H√ÄM ƒê·ªåC D·ªÆ LI·ªÜU TH·∫¨T T·ª™ FOLDER DATA
# ==========================================
def load_data_from_folder():
    data_path = "data" # Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu
    if not os.path.exists(data_path):
        os.makedirs(data_path)
        return None, "Th∆∞ m·ª•c 'data' kh√¥ng t·ªìn t·∫°i. Vui l√≤ng t·∫°o v√† b·ªè file CSV/Excel v√†o."

    files = [f for f in os.listdir(data_path) if f.endswith(('.csv', '.xlsx', '.xls'))]
    if not files:
        return None, "Kh√¥ng t√¨m th·∫•y file .csv ho·∫∑c .xlsx n√†o trong th∆∞ m·ª•c 'data'."
    
    return files, None

def process_dataframe(df, text_col, label_col):
    """Chuy·ªÉn ƒë·ªïi DataFrame th√†nh format training"""
    # 1. L·ªçc d·ªØ li·ªáu r·ªóng
    df = df.dropna(subset=[text_col, label_col])
    
    # 2. X·ª≠ l√Ω nh√£n (Label) v·ªÅ 0 v√† 1
    # Logic: N·∫øu nh√£n l√† s·ªë (1-5 sao): >=4 l√† 1 (T·ªët), <=3 l√† 0 (T·ªá)
    # N·∫øu nh√£n l√† ch·ªØ (POS/NEG): 'POS'/'Positive' l√† 1, c√≤n l·∫°i 0
    
    y_data = []
    
    # Ki·ªÉm tra ki·ªÉu d·ªØ li·ªáu c·ªßa c·ªôt label
    first_val = df[label_col].iloc[0]
    
    try:
        # Tr∆∞·ªùng h·ª£p Label l√† s·ªë (VD: 1,2,3,4,5 ho·∫∑c 0,1)
        if isinstance(first_val, (int, float, np.number)):
            # N·∫øu ch·ªâ c√≥ 0 v√† 1 th√¨ gi·ªØ nguy√™n
            unique_vals = df[label_col].unique()
            if set(unique_vals).issubset({0, 1}):
                y_data = df[label_col].values
            else:
                # N·∫øu l√† thang ƒëi·ªÉm 5 (VD: shopee)
                y_data = [1 if x >= 4 else 0 for x in df[label_col]]
        else:
            # Tr∆∞·ªùng h·ª£p Label l√† ch·ªØ
            y_data = [1 if str(x).lower() in ['pos', 'positive', 't·ªët', 'tich cuc', '1'] else 0 for x in df[label_col]]
    except:
        return None, None, None, "L·ªói khi x·ª≠ l√Ω c·ªôt Label. H√£y ƒë·∫£m b·∫£o c·ªôt Label ch·ª©a s·ªë ho·∫∑c ph√¢n lo·∫°i r√µ r√†ng."

    # 3. L·∫•y text
    reviews = df[text_col].astype(str).tolist()
    
    # 4. Tokenize (T√°ch t·ª´ v√† t·∫°o b·ªô t·ª´ ƒëi·ªÉn)
    # N·ªëi t·∫•t c·∫£ text l·∫°i ƒë·ªÉ ƒë·∫øm t·ª´
    all_text = " ".join(reviews).lower().replace('.', '').replace(',', '')
    words = all_text.split()
    count_words = Counter(words)
    
    # Ch·ªâ gi·ªØ l·∫°i nh·ªØng t·ª´ xu·∫•t hi·ªán > 1 l·∫ßn ƒë·ªÉ gi·∫£m nhi·ªÖu
    sorted_words = [w for w, c in count_words.most_common() if c > 1]
    vocab = {w: i+1 for i, w in enumerate(sorted_words)}
    
    # M√£ h√≥a reviews th√†nh s·ªë
    reviews_int = []
    for r in reviews:
        r_clean = r.lower().replace('.', '').replace(',', '').split()
        reviews_int.append([vocab.get(w, 0) for w in r_clean])
        
    # Padding (Cho b·∫±ng ƒë·ªô d√†i 50)
    seq_len = 50
    features = np.zeros((len(reviews_int), seq_len), dtype=int)
    for i, row in enumerate(reviews_int):
        features[i, -min(len(row), seq_len):] = np.array(row)[:seq_len]
        
    # Convert sang Tensor
    X = torch.from_numpy(features)
    y = torch.from_numpy(np.array(y_data)).float()
    
    return X, y, vocab, None

# ==========================================
# 2. GIAO DI·ªÜN CH√çNH
# ==========================================
def show():
    st.markdown('<div style="background-color:rgba(255,255,255,0.9); padding:20px; border-radius:15px;">', unsafe_allow_html=True)
    st.title("üî• Train PyTorch v·ªõi D·ªØ Li·ªáu Th·∫≠t")
    st.write("Hu·∫•n luy·ªán m√¥ h√¨nh t·ª´ c√°c file c√≥ trong th∆∞ m·ª•c `data/`.")

    if not HAS_DEPS:
        st.error("‚ö†Ô∏è Thi·∫øu file `model_utils.py` ho·∫∑c th∆∞ vi·ªán `torch`.")
        return

    # --- B∆Ø·ªöC 1: CH·ªåN FILE D·ªÆ LI·ªÜU ---
    files, err = load_data_from_folder()
    
    if err:
        st.warning(f"‚ö†Ô∏è {err}")
        st.info("üí° H√£y copy file d·ªØ li·ªáu (CSV ho·∫∑c Excel) v√†o th∆∞ m·ª•c `data` c·ªßa d·ª± √°n.")
        return

    col_file, col_conf = st.columns([1, 2])
    
    with col_file:
        st.subheader("1. Ch·ªçn File")
        selected_file = st.selectbox("Ch·ªçn file d·ªØ li·ªáu:", files)
        file_path = os.path.join("data", selected_file)
        
        # ƒê·ªçc file ƒë·ªÉ l·∫•y t√™n c·ªôt
        try:
            if selected_file.endswith('.csv'):
                df = pd.read_csv(file_path)
            else:
                df = pd.read_excel(file_path)
            st.success(f"ƒê√£ ƒë·ªçc {len(df)} d√≤ng d·ªØ li·ªáu.")
        except Exception as e:
            st.error(f"L·ªói ƒë·ªçc file: {e}")
            return

    with col_conf:
        st.subheader("2. C·∫•u h√¨nh C·ªôt")
        all_columns = df.columns.tolist()
        
        c1, c2 = st.columns(2)
        with c1:
            text_col = st.selectbox("C·ªôt ch·ª©a n·ªôi dung (Review):", all_columns, index=0)
        with c2:
            # C·ªë g·∫Øng t·ª± ƒë·ªông t√¨m c·ªôt label
            label_index = 0
            for i, col in enumerate(all_columns):
                if col.lower() in ['label', 'rating', 'score', 'sentiment', 'nh√£n', 'ƒëi·ªÉm']:
                    label_index = i
                    break
            label_col = st.selectbox("C·ªôt ch·ª©a nh√£n (Label/Rating):", all_columns, index=label_index)
            
        st.caption("üìù V√≠ d·ª•: C·ªôt n·ªôi dung l√† 'comment', c·ªôt nh√£n l√† 'rating' (1-5 sao) ho·∫∑c 'label' (0/1).")

    st.write("---")

    # --- B∆Ø·ªöC 2: TRAIN MODEL ---
    col_train, col_log = st.columns([1, 2])
    
    with col_train:
        st.subheader("3. Hu·∫•n luy·ªán")
        epochs = st.number_input("S·ªë v√≤ng l·∫∑p (Epochs):", 1, 100, 5)
        batch_size = st.selectbox("Batch Size:", [16, 32, 64], index=1)
        lr = st.select_slider("Learning Rate:", options=[0.01, 0.005, 0.001], value=0.005)
        
        btn_train = st.button("üöÄ B·∫Øt ƒë·∫ßu Train", type="primary")

    with col_log:
        st.subheader("üìà Ti·∫øn tr√¨nh")
        log_area = st.empty()
        chart_loss = st.empty()
        
        if btn_train:
            status = st.info("üîÑ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
            
            # X·ª≠ l√Ω data th·∫≠t
            X, y, vocab, err_msg = process_dataframe(df, text_col, label_col)
            
            if err_msg:
                st.error(err_msg)
            else:
                status.info(f"‚úÖ ƒê√£ x·ª≠ l√Ω xong! Vocab: {len(vocab)} t·ª´. B·∫Øt ƒë·∫ßu train...")
                time.sleep(1)
                
                # --- CODE TRAIN (GI·ªêNG C≈®) ---
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                
                # Dataset & Loader
                dataset = TensorDataset(X, y)
                train_loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, drop_last=False)
                
                # Init Model
                vocab_size = len(vocab) + 1
                model = SentimentLSTM(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, 1, N_LAYERS)
                model.to(device)
                
                criterion = nn.BCELoss()
                optimizer = optim.Adam(model.parameters(), lr=lr)
                
                model.train()
                loss_history = []
                progress_bar = st.progress(0)
                
                start_time = time.time()
                
                for e in range(epochs):
                    h = model.init_hidden(batch_size, device)
                    epoch_losses = []
                    
                    for inputs, labels in train_loader:
                        # Handle batch l·∫ª
                        curr_bs = inputs.size(0)
                        if curr_bs != batch_size:
                            h = model.init_hidden(curr_bs, device)
                        else:
                            h = tuple([each.data for each in h])
                            
                        inputs, labels = inputs.to(device), labels.to(device)
                        
                        model.zero_grad()
                        output, h = model(inputs, h)
                        
                        loss = criterion(output, labels)
                        loss.backward()
                        nn.utils.clip_grad_norm_(model.parameters(), 5)
                        optimizer.step()
                        
                        epoch_losses.append(loss.item())
                    
                    avg_loss = np.mean(epoch_losses)
                    loss_history.append(avg_loss)
                    
                    # Update Chart & Log
                    chart_loss.line_chart(loss_history)
                    log_area.text(f"Epoch {e+1}/{epochs} | Loss: {avg_loss:.4f}")
                    progress_bar.progress((e + 1) / epochs)
                
                # L∆∞u Model
                if not os.path.exists("models"):
                    os.makedirs("models")
                torch.save(model.state_dict(), "models/sentiment_model.pth")
                with open("models/vocab.pkl", "wb") as f:
                    pickle.dump(vocab, f)
                
                status.success("üéâ Hu·∫•n luy·ªán ho√†n t·∫•t! Model ƒë√£ ƒë∆∞·ª£c l∆∞u.")
                st.balloons()
                st.info("üëâ B√¢y gi·ªù b·∫°n c√≥ th·ªÉ qua trang **Analysis** ƒë·ªÉ ki·ªÉm tra.")

    st.markdown('</div>', unsafe_allow_html=True)
import time # Import th√™m time ƒë·ªÉ sleep

if __name__ == "__main__":
    show()
