# dump_model_object.py
# ==========================================
# PRO UPGRADE: English Sentiment Analysis Pipeline
# ==========================================

import os
import joblib
import pandas as pd
import numpy as np
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# --- C·∫§U H√åNH ---
DATA_DIR = "data"
MODEL_DIR = "models"
MODEL_PATH = os.path.join(MODEL_DIR, "model_en.pkl")

def clean_text(text):
    """H√†m l√†m s·∫°ch d·ªØ li·ªáu c∆° b·∫£n"""
    if not isinstance(text, str): return ""
    text = text.lower()
    # Gi·ªØ l·∫°i ch·ªØ c√°i ti·∫øng Anh v√† d·∫•u c√¢u c∆° b·∫£n, lo·∫°i b·ªè k√Ω t·ª± l·∫°
    text = re.sub(r'[^a-zA-Z\s]', ' ', text)
    return text.strip()

def load_real_data():
    """T·ª± ƒë·ªông t√¨m v√† load d·ªØ li·ªáu t·ª´ file CSV trong th∆∞ m·ª•c data/"""
    all_texts = []
    all_labels = []
    
    # D·ªØ li·ªáu m·∫´u (Backup n·∫øu kh√¥ng t√¨m th·∫•y file)
    fallback_texts = ["Good job", "Bad quality", "Excellent", "Poor service", "Normal"]
    fallback_labels = ["positive", "negative", "positive", "negative", "neutral"]

    if not os.path.exists(DATA_DIR):
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c data/. D√πng d·ªØ li·ªáu m·∫´u.")
        return fallback_texts, fallback_labels

    print(f"üìÇ ƒêang qu√©t d·ªØ li·ªáu trong {DATA_DIR}...")
    
    # Qu√©t file CSV/Excel
    files = [f for f in os.listdir(DATA_DIR) if f.endswith(('.csv', '.xlsx'))]
    
    found_data = False
    for f in files:
        # B·ªè qua file metadata
        if "metadata" in f.lower(): continue
        
        path = os.path.join(DATA_DIR, f)
        try:
            df = pd.read_csv(path) if f.endswith('.csv') else pd.read_excel(path)
            
            # Chu·∫©n h√≥a t√™n c·ªôt
            df.columns = [c.strip().lower() for c in df.columns]
            
            # T√¨m c·ªôt text v√† label ph√π h·ª£p
            text_col = next((c for c in df.columns if c in ['text', 'content', 'review']), None)
            label_col = next((c for c in df.columns if c in ['sentiment', 'label']), None)
            
            if text_col and label_col:
                print(f"   -> ƒê·ªçc file: {f} ({len(df)} d√≤ng)")
                # Clean text v√† th√™m v√†o list
                cleaned_texts = df[text_col].apply(clean_text).tolist()
                labels = df[label_col].astype(str).str.strip().tolist()
                
                all_texts.extend(cleaned_texts)
                all_labels.extend(labels)
                found_data = True
        except Exception as e:
            print(f"   ‚ùå L·ªói ƒë·ªçc file {f}: {e}")

    if not found_data:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu h·ª£p l·ªá. D√πng d·ªØ li·ªáu m·∫´u.")
        return fallback_texts, fallback_labels
    
    return all_texts, all_labels

def train_and_dump():
    # 1. Load Data
    print("\n--- 1. LOAD DATA ---")
    texts, labels = load_real_data()
    print(f"‚úÖ T·ªïng d·ªØ li·ªáu: {len(texts)} d√≤ng")

    # 2. Split Data (Train 80% - Test 20%)
    # Stratify ƒë·ªÉ ƒë·∫£m b·∫£o t·ª∑ l·ªá nh√£n ƒë·ªÅu nhau
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            texts, labels, test_size=0.2, random_state=42, stratify=labels
        )
    except ValueError:
        # N·∫øu d·ªØ li·ªáu qu√° √≠t ho·∫∑c 1 nh√£n ch·ªâ c√≥ 1 d√≤ng th√¨ kh√¥ng stratify ƒë∆∞·ª£c
        X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

    # 3. T·∫°o Pipeline (QUAN TR·ªåNG NH·∫§T)
    # Pipeline gi√∫p g·ªôp vectorizer v√† model th√†nh 1 kh·ªëi th·ªëng nh·∫•t
    print("\n--- 2. TRAINING ---")
    model_pipeline = Pipeline([
        ('tfidf', TfidfVectorizer(stop_words='english', max_features=5000)),
        ('clf', LogisticRegression(solver='liblinear', multi_class='auto'))
    ])

    model_pipeline.fit(X_train, y_train)
    print("‚úÖ Training ho√†n t·∫•t.")

    # 4. ƒê√°nh gi√° Model
    print("\n--- 3. EVALUATION ---")
    y_pred = model_pipeline.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"üéØ ƒê·ªô ch√≠nh x√°c (Accuracy): {acc:.2%}")
    print("\nChi ti·∫øt:")
    print(classification_report(y_test, y_pred, zero_division=0))

    # 5. L∆∞u Model
    print("\n--- 4. SAVING ---")
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR)

    # Ch·ªâ c·∫ßn l∆∞u 1 file duy nh·∫•t (ƒë√£ ch·ª©a c·∫£ vectorizer b√™n trong)
    joblib.dump(model_pipeline, MODEL_PATH)
    
    print(f"üì¶ ƒê√£ l∆∞u Pipeline v√†o: {MODEL_PATH}")
    print("üí° M·∫πo: Khi d√πng, ch·ªâ c·∫ßn load file n√†y v√† g·ªçi .predict() tr·ª±c ti·∫øp v·ªõi text th√¥.")

if __name__ == "__main__":
    train_and_dump()
